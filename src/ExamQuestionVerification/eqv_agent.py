import os
import asyncio
import socket
from typing import List, Dict, AsyncGenerator, Optional
import concurrent.futures

from agentscope_runtime.engine.agents.agentscope_agent import AgentScopeAgent
from agentscope_runtime.sandbox.tools.function_tool import function_tool
from agentscope_runtime.engine import Runner
from agentscope_runtime.engine.services.session_history_service import InMemorySessionHistoryService
from agentscope_runtime.engine.services.memory_service import InMemoryMemoryService
from agentscope_runtime.engine.services.context_manager import ContextManager
from agentscope_runtime.engine.services.sandbox_service import SandboxService
from agentscope_runtime.engine.services.environment_manager import EnvironmentManager
from agentscope_runtime.engine.deployers.local_deployer import LocalDeployManager
from agentscope_runtime.engine.schemas.agent_schemas import (
    Message,
    RunStatus,
    AgentRequest,
)

from agentscope.model import OpenAIChatModel, DashScopeChatModel
from agentscope.agent import ReActAgent
from agentscope.formatter import DeepSeekChatFormatter, DashScopeChatFormatter

from exam_question_verification import build_exam_verifier
from schemas import ExamQuestion, VerificationResult
from prompts import PROMPTS

# ---------------------------
# åŠ è½½é…ç½®æ–‡ä»¶
# ---------------------------
import yaml
conf_path = os.path.join(os.path.dirname(__file__), "conf.yaml")
with open(conf_path, "r", encoding="utf-8") as f:
    CONF = yaml.safe_load(f)

# ---------------------------
# è€ƒè¯•é¢˜ç›®æ ¸æŸ¥+ä¿®æ­£å·¥å…·å®ä¾‹æ„å»º
# ---------------------------
LLM_BINDING = CONF.get("LLM_BINDING") or os.getenv("LLM_BINDING") or "deepseek"
MODEL_NAME = CONF.get("MODEL_NAME") or os.getenv("MODEL_NAME") or "deepseek-chat"
API_KEY = CONF.get("API_KEY") or os.getenv("API_KEY") or ""
BASE_URL = CONF.get("BASE_URL") or os.getenv("BASE_URL") or "https://api.deepseek.com"

verifier = build_exam_verifier(
    llm_binding=LLM_BINDING if LLM_BINDING in ("deepseek", "dashscope") else "deepseek",
    model_name=MODEL_NAME,
    api_key=API_KEY,
    base_url=BASE_URL,
    stream=False
)

@function_tool(name="verify_exam_question_tool")
def verify_exam_question_tool(
    question: str,
    answer: str,
    question_type: str,
    knowledge_point: str = "",
    knowledge_point_description: str = "",
    extra_requirement: Optional[str] = None,
) -> dict:
    """
    æ ¸æŸ¥è€ƒé¢˜æ˜¯å¦åˆè§„ï¼Œè¿”å›æ ¸æŸ¥ç»“æœå’Œå»ºè®®ã€‚
    
    Args:
        question: è€ƒè¯•é¢˜ç›®
        answer: è€ƒè¯•é¢˜ç›®ç­”æ¡ˆ
        question_type: è€ƒè¯•é¢˜ç›®ç±»å‹
        knowledge_point: è€ƒè¯•é¢˜ç›®æ‰€å±çš„çŸ¥è¯†ç‚¹
        knowledge_point_description: è€ƒè¯•é¢˜ç›®æ‰€å±çš„çŸ¥è¯†ç‚¹çš„å…·ä½“æè¿°
        extra_requirement: è€ƒè¯•é¢˜ç›®é¢å¤–è¦æ±‚
    
    Returns:
        dict: åŒ…å«æ ¸æŸ¥ç»“æœå’Œå»ºè®®çš„å­—å…¸ã€‚
    """
    eq = ExamQuestion(
        question=question,
        answer=answer,
        question_type=question_type,
        knowledge_point=knowledge_point,
        knowledge_point_description=knowledge_point_description,
        extra_requirement=extra_requirement,
    )

    def _run_verify():
        return asyncio.run(verifier.verify_exam_question(eq))

    with concurrent.futures.ThreadPoolExecutor(max_workers=4) as executor:
        future = executor.submit(_run_verify)
        res = future.result()

    return res.model_dump()

@function_tool(name="fix_exam_question_tool")
def fix_exam_question_tool(
    Compliance: bool,
    suggestion: str,
    question: str,
    answer: str,
    question_type: str,
    knowledge_point: str = "",
    knowledge_point_description: str = "",
    extra_requirement: Optional[str] = None,
) -> dict:
    """
    åŸºäºæ ¸æŸ¥ç»“æœä¿®æ­£è€ƒé¢˜ï¼Œè¿”å›ä¿®æ­£åçš„è€ƒé¢˜ã€‚
    
    Args:
        Compliance: è€ƒè¯•é¢˜ç›®æ˜¯å¦åˆè§„
        suggestion: è€ƒè¯•é¢˜ç›®ä¿®æ­£å»ºè®®
        question: è€ƒè¯•é¢˜ç›®
        answer: è€ƒè¯•é¢˜ç›®ç­”æ¡ˆ
        question_type: è€ƒè¯•é¢˜ç›®ç±»å‹
        knowledge_point: è€ƒè¯•é¢˜ç›®æ‰€å±çš„çŸ¥è¯†ç‚¹
        knowledge_point_description: è€ƒè¯•é¢˜ç›®æ‰€å±çš„çŸ¥è¯†ç‚¹çš„å…·ä½“æè¿°
        extra_requirement: è€ƒè¯•é¢˜ç›®é¢å¤–è¦æ±‚
    
    Returns:
        dict: ä¿®æ­£åçš„è€ƒé¢˜å¯¹è±¡çš„å­—å…¸ã€‚
    """
    eq = ExamQuestion(
        question=question,
        answer=answer,
        question_type=question_type,
        knowledge_point=knowledge_point,
        knowledge_point_description=knowledge_point_description,
        extra_requirement=extra_requirement,
    )   
    vr = VerificationResult(
        Compliance=Compliance,
        suggestion=suggestion,
    )

    def _run_fix():
        return asyncio.run(verifier.fix_exam_question(eq, vr))

    with concurrent.futures.ThreadPoolExecutor(max_workers=4) as executor:
        future = executor.submit(_run_fix)
        new_eq = future.result()

    return new_eq.model_dump()

@function_tool(name="verify_and_fix_exam_question_tool")
def verify_and_fix_exam_question_tool(
    question: str,
    answer: str,
    question_type: str,
    knowledge_point: str = "",
    knowledge_point_description: str = "",
    extra_requirement: Optional[str] = None,
) -> dict:
    """
    ä¸€é”®æ ¸æŸ¥å’Œä¿®æ­£è€ƒé¢˜ã€‚
    
    Args:
        question: è€ƒè¯•é¢˜ç›®
        answer: è€ƒè¯•é¢˜ç›®ç­”æ¡ˆ
        question_type: è€ƒè¯•é¢˜ç›®ç±»å‹
        knowledge_point: è€ƒè¯•é¢˜ç›®æ‰€å±çš„çŸ¥è¯†ç‚¹
        knowledge_point_description: è€ƒè¯•é¢˜ç›®æ‰€å±çš„çŸ¥è¯†ç‚¹çš„å…·ä½“æè¿°
        extra_requirement: è€ƒè¯•é¢˜ç›®é¢å¤–è¦æ±‚
    
    Returns:
        dict: æ ¸æŸ¥å¹¶ä¿®å¤åçš„è€ƒé¢˜ã€‚
    """
    eq = ExamQuestion(
        question=question,
        answer=answer,
        question_type=question_type,
        knowledge_point=knowledge_point,
        knowledge_point_description=knowledge_point_description,
        extra_requirement=extra_requirement,
    )

    max_fix_attempts = int(CONF.get("MAX_FIX_ATTEMPTS", "3") or "3")
    def _run_verify_and_fix():
        return asyncio.run(verifier.main(eq, max_fix_attempts))

    with concurrent.futures.ThreadPoolExecutor(max_workers=4) as executor:
        future = executor.submit(_run_verify_and_fix)
        res = future.result()

    return res.model_dump()


class ExamQuestionVerificationAgent:
    def __init__(self) -> None:
        self.llm_binding = LLM_BINDING
        self.model_name = MODEL_NAME
        self.api_key = API_KEY
        self.base_url = BASE_URL

        self.tools = [
            verify_exam_question_tool,
            fix_exam_question_tool,
            verify_and_fix_exam_question_tool
        ]

        self.agent = self.create_exam_question_verification_agent()

        self.connected = False

    async def connect(self, session_id: str, user_id: str) -> None:
        """
        è¿æ¥åˆ°æ²™ç®±ç¯å¢ƒï¼Œåˆå§‹åŒ–ä¼šè¯å†å²ã€å†…å­˜æœåŠ¡ã€æ²™ç®±æœåŠ¡å’Œä¸Šä¸‹æ–‡ç®¡ç†å™¨ã€‚
        Args:
            session_id: ä¼šè¯å†å²æœåŠ¡å’Œæ²™ç®±æœåŠ¡çš„ä¼šè¯ID
            user_id: ä¼šè¯å†å²æœåŠ¡å’Œæ²™ç®±æœåŠ¡çš„ç”¨æˆ·ID
        """
        # åˆå§‹åŒ–ä¼šè¯å†å²æœåŠ¡
        session_history_service = InMemorySessionHistoryService()
        await session_history_service.create_session(session_id, user_id)

        # åˆå§‹åŒ–å†…å­˜æœåŠ¡
        self.memory_service = InMemoryMemoryService()
        await self.memory_service.start()

        # åˆå§‹åŒ–æ²™ç®±
        # TODO: è¿æ¥è¿œç¨‹æ²™ç®±åº”è¯¥è¿æ¥åˆ°ä»€ä¹ˆç±»å‹çš„æ²™ç®±ï¼Œbaseã€browser or filesystemï¼Ÿ
        # sandbox_type = os.getenv("AGENT_RUNTIME_SANDBOX_TYPE") or "local"
        # if sandbox_type == "local":
        #     self.sandbox_service = SandboxService()
        # elif sandbox_type == "remote":
        #     sandbox_host = CONF.get("AGENT_RUNTIME_SANDBOX_HOST") or os.getenv("AGENT_RUNTIME_SANDBOX_HOST", "localhost")
        #     sandbox_port = CONF.get("AGENT_RUNTIME_SANDBOX_PORT") or os.getenv("AGENT_RUNTIME_SANDBOX_PORT", "8002")
        #     sandbox_url = f"http://{sandbox_host}:{sandbox_port}"
        #     self.sandbox_service = SandboxService(
        #         base_url=sandbox_url,
        #     )
        # else:
        #     raise ValueError(f"ä¸æ”¯æŒçš„æ²™ç®±ç±»å‹: {sandbox_type}, è¯·é€‰æ‹© 'local' æˆ– 'remote'")
        # await self.sandbox_service.start()
    
        # åˆ›å»ºä¸Šä¸‹æ–‡ç®¡ç†å™¨
        self.context_manager = ContextManager(
            memory_service=self.memory_service,
            session_history_service=session_history_service
        )
        # åˆ›å»ºç¯å¢ƒç®¡ç†å™¨
        # self.environment_manager = EnvironmentManager(
        #     sandbox_service=self.sandbox_service,
        # )

        # è‹¥éœ€è¦ä½¿ç”¨æ²™ç®±å·¥å…·
        # from agentscope_runtime.sandbox.tools.filesystem import read_file
        # sandboxes = self.sandbox_service.connect(
        #     session_id=session_id,
        #     user_id=user_id,
        #     tools=[],
        # )
        # print(f"é…ç½®äº†{len(sandboxes)}ä¸ªæ²™ç®±")

        runer = Runner(
            agent=self.agent,
            context_manager=self.context_manager,
            # environment_manager=self.environment_manager,
        )
        self.runner = runer
        self.connected = True

    async def chat(
        self,
        session_id: str,
        user_id: str,
        chat_messages: List[Message],
    ) -> AsyncGenerator[Dict, None]:
        if not self.connected:
            await self.connect(session_id, user_id)

        convert_messages = []
        for chat_message in chat_messages:
            convert_messages.append(
                Message(
                    role=chat_message.role,
                    content=chat_message.content,
                )
            )
        request = AgentRequest(input=convert_messages, session_id=session_id)
        request.tools = []
        async for message in self.runner.stream_query(
            user_id=user_id,
            request=request,
        ):
            if (
                message.object == "message"
                and RunStatus.Completed == message.status
            ):
                yield message.content
    
    async def deploy(self) -> None:
        """éƒ¨ç½²agent"""
        if not self.connected:
            raise ValueError("ä»£ç†æœªåŒ…è£…ä¸ºRunnerç¯å¢ƒ, è¯·å…ˆè°ƒç”¨ connect æ–¹æ³•ã€‚")
        
        host = CONF.get("AGENT_RUNTIME_HOST") or os.getenv("AGENT_RUNTIME_HOST", "0.0.0.0")
        port = int(CONF.get("AGENT_RUNTIME_PORT") or os.getenv("AGENT_RUNTIME_PORT", "8001"))
        endpoint_path = CONF.get("AGENT_RUNTIME_ENDPOINT_PATH") or os.getenv("AGENT_RUNTIME_ENDPOINT_PATH", "")

        def _get_accessible_host(host: str) -> str:
            """è·å–å¯è®¿é—®çš„ä¸»æœºIPåœ°å€ã€‚"""
            try:
                if host in ("0.0.0.0", "", None):
                    s = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
                    try:
                        s.connect(("8.8.8.8", 80))
                        ip = s.getsockname()[0]
                    except Exception:
                        ip = socket.gethostbyname(socket.gethostname())
                        if ip.startswith("127."):
                            ip = "127.0.0.1"
                    finally:
                        s.close()
                    return ip
                return host
            except Exception:
                return "127.0.0.1"

        deploy_manager = LocalDeployManager(
            host=_get_accessible_host(host),
            port=port,
        )
        deploy_result = await self.runner.deploy(
            deploy_manager=deploy_manager,
            endpoint_path=endpoint_path,
            stream=True,
        )

        # print(f"ğŸš€æ™ºèƒ½ä½“éƒ¨ç½²åœ¨: {deploy_result}")
        # print(f"ğŸŒæœåŠ¡URL: http://{host}:{port}")
        # print(f"ğŸ’š å¥åº·æ£€æŸ¥: http://{host}:{port}/health")

        await asyncio.Event().wait()

    async def close(self) -> None:
        """å…³é—­æ‰€æœ‰æœåŠ¡ä¸æ²™ç®±è¿æ¥ã€‚"""
        await self.memory_service.stop()
        # await self.sandbox_service.stop()

    def create_exam_question_verification_agent(self) -> AgentScopeAgent:
        """åˆ›å»ºè€ƒè¯•é—®é¢˜æ ¸æŸ¥æ™ºèƒ½ä½“ã€‚"""

        # ä¸»ä»£ç†ç”¨æµå¼æ¨¡å‹ï¼Œæ”¯æŒå¼‚æ­¥è¿­ä»£è¾“å‡º
        if self.llm_binding == "deepseek":
            model = OpenAIChatModel(
                model_name=self.model_name,
                api_key=self.api_key,
                client_args={"base_url": self.base_url},
                stream=True,
            )
            formatter = DeepSeekChatFormatter()
        elif self.llm_binding == "dashscope":
            model = DashScopeChatModel(
                model_name=self.model_name,
                api_key=self.api_key,
                stream=True,
            )
            formatter = DashScopeChatFormatter()
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„LLMç»‘å®š: {self.llm_binding}")

        return AgentScopeAgent(
            name="eqv_plan_agent",
            model=model,
            tools=self.tools,
            agent_config={
                "sys_prompt": PROMPTS["agent_sys_prompt"],
                # å…³é”®ï¼šæä¾›formatterï¼ŒæŠŠå†…å®¹å—åˆå¹¶ä¸ºå­—ç¬¦ä¸²ï¼Œé¿å…contentæ˜¯åˆ—è¡¨
                "formatter": formatter,
            },
            agent_builder=ReActAgent,
        )
